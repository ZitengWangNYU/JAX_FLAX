{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flax.linen.scan module can be used to reduce the whole repeated or iterative computation graph into a single interation, therefore reduces the graph memory and compilation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-06-02 20:21:11,002:jax._src.xla_bridge:795: A Google TPU may be present on this machine, but either a TPU-enabled jaxlib or libtpu is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# Auto-reload modules so we can edit the code and have it automatically reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import timeit\n",
    "\n",
    "import jax\n",
    "import jaxlib\n",
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LEN = 32\n",
    "HIDDEN_DIM = 512\n",
    "LAYERS = 42\n",
    "NUM_HEADS = 4\n",
    "DTYPE = jnp.float32\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "dummy_input = jax.random.normal(rng, (1, SEQ_LEN, HIDDEN_DIM))\n",
    "input = jax.random.normal(rng, (BATCH_SIZE, SEQ_LEN, HIDDEN_DIM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def measure_time(fn, params, input, num_runs=5):\n",
    "  total_time = timeit.timeit(\n",
    "    lambda: jax.tree.map(lambda x: x.block_until_ready(), fn(params, input)),\n",
    "    number=num_runs\n",
    "  )\n",
    "  avg_time = total_time / num_runs\n",
    "  if avg_time < 1e-3:\n",
    "    return f\"{avg_time * 1e6:.2f} Î¼s\"\n",
    "  elif avg_time < 1:\n",
    "    return f\"{avg_time * 1e3:.2f} ms\"\n",
    "  else:\n",
    "    return f\"{avg_time:.2f} s\"\n",
    "\n",
    "def compare_time(fn, params, input, num_runs=5):\n",
    "  assert not isinstance(fn, jaxlib._jax.PjitFunction), \"Function appears to be jitted\"\n",
    "  jit_fn = jax.jit(fn)\n",
    "  # print(f\"Average time for the regular apply: {measure_time(fn, params, input, num_runs)}\")\n",
    "  # print(f\"Average time for the first JIT call: {measure_time(jit_fn, params, input, num_runs)}\")\n",
    "  output = jit_fn(params, input)\n",
    "  print(f\"Average time for the subsequent JIT calls: {measure_time(jit_fn, params, input, num_runs)}\")\n",
    "\n",
    "def print_cost_analysis(cost, show_utilization=False):\n",
    "    \"\"\"\n",
    "    Pretty-print the cost analysis dictionary returned by:\n",
    "        jax.jit(fn).lower(...).compile().cost_analysis()\n",
    "    \n",
    "    Args:\n",
    "        cost: Dictionary containing cost analysis metrics\n",
    "        show_utilization: Whether to print per-layer utilization metrics\n",
    "    \"\"\"\n",
    "    print(\"=== JAX Cost Analysis ===\")\n",
    "\n",
    "    # Total memory accessed\n",
    "    total_mem = cost.get('bytes accessedout{}', 0)\n",
    "    print(f\"Total estimated memory accessed: {total_mem / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "    # Find peak memory estimate across all ops\n",
    "    peak_mem = max(\n",
    "        val for key, val in cost.items() if key.startswith('bytes accessedout{')\n",
    "    )\n",
    "    print(f\"Estimated peak memory usage: {peak_mem / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "    # Total FLOPs\n",
    "    flops = cost.get('flops', 0)\n",
    "    print(f\"Estimated FLOPs: {flops / 1e9:.3f} GFLOPs\")\n",
    "\n",
    "    # Transcendental operations\n",
    "    trans = cost.get('transcendentals', 0)\n",
    "    print(f\"Transcendental ops (exp, sin, etc.): {int(trans)}\")\n",
    "\n",
    "    # Optimal execution time (TPU internal estimate)\n",
    "    optimal_time = cost.get('optimal_seconds', None)\n",
    "    if optimal_time is not None:\n",
    "        print(f\"Estimated optimal execution time: {optimal_time * 1e3:.3f} ms\")\n",
    "\n",
    "    if show_utilization:\n",
    "        print(\"=== Per-Layer Utilization (if available) ===\")\n",
    "        utilizations = {\n",
    "            k: v for k, v in cost.items() if k.startswith('utilization')\n",
    "        }\n",
    "\n",
    "        if utilizations:\n",
    "            for key, value in sorted(utilizations.items()):\n",
    "                print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(\"No detailed utilization metrics found.\")\n",
    "    print(); print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic iterative module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for the subsequent JIT calls: 641.35 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'layer_0': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_1': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_10': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_11': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_12': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_13': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_14': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_15': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_16': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_17': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_18': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_19': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_2': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_20': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_21': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_22': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_23': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_24': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_25': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_26': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_27': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_28': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_29': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_3': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_30': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_31': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_32': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_33': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_34': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_35': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_36': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_37': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_38': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_39': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_4': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_40': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_41': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_5': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_6': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_7': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_8': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}},\n",
       "  'layer_9': {'Dense_0': {'bias': (512,), 'kernel': (512, 512)},\n",
       "   'self_attention': {'key': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'out': {'bias': (512,), 'kernel': (4, 128, 512)},\n",
       "    'query': {'bias': (4, 128), 'kernel': (512, 4, 128)},\n",
       "    'value': {'bias': (4, 128), 'kernel': (512, 4, 128)}}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleBlock(nn.Module):\n",
    "    hidden_dim: int\n",
    "    num_heads: int\n",
    "    dtype: jnp.dtype\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, attention_mask=None):\n",
    "        out = {}\n",
    "        out[\"input_hidden_state\"] = x\n",
    "        x += nn.SelfAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            kernel_init=nn.initializers.xavier_uniform(),\n",
    "            bias_init=nn.initializers.zeros,\n",
    "            dtype=self.dtype,\n",
    "            name=\"self_attention\"\n",
    "\t\t\t\t\t)(x, attention_mask)\n",
    "        out[\"+self_attention\"] = x\n",
    "        x += nn.Dense(features=self.hidden_dim)(x)\n",
    "        out[\"+dense\"] = x\n",
    "        return x, out\n",
    "\n",
    "class MyIterativeModule(nn.Module):\n",
    "    hidden_dim: int\n",
    "    num_layers: int\n",
    "    num_heads: int\n",
    "    dtype: jnp.dtype\n",
    "    \n",
    "    def setup(self):\n",
    "        self.blocks = [\n",
    "            SimpleBlock(\n",
    "                name=f\"layer_{i}\",\n",
    "                hidden_dim=self.hidden_dim,\n",
    "                num_heads=self.num_heads,\n",
    "                dtype=self.dtype\n",
    "\t\t\t\t\t\t) \n",
    "            for i in range(self.num_layers)  # Use num_layers instead of hardcoded 3\n",
    "        ]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = {}\n",
    "        for i, block in enumerate(self.blocks):\n",
    "          x, layer_out = block(x)\n",
    "          out[f\"layer_{i}\"] = layer_out\n",
    "        return x, out\n",
    "\n",
    "model = MyIterativeModule(hidden_dim=HIDDEN_DIM, num_layers=LAYERS, num_heads=NUM_HEADS, dtype=DTYPE)\n",
    "params = model.init(init_rng, dummy_input)\n",
    "\n",
    "compare_time(model.apply, params, input)\n",
    "\n",
    "jax.tree.map(jnp.shape, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of different scan configurations for nn.scan\n",
    "scan_args_list = [\n",
    "    # Configuration 1: \n",
    "    # - No parameter axes (shared parameters across layers)\n",
    "    # - Broadcast parameters to all layers\n",
    "    # - Don't split RNGs for parameters\n",
    "    # - Input/Output along axis 0 (batch dimension)\n",
    "    {\n",
    "        \"variable_axes\": {},  # No parameter axes (shared params)\n",
    "        \"variable_broadcast\": \"params\",  # Broadcast params to all layers\n",
    "        \"split_rngs\": {\"params\": False},  # Don't split RNGs for params\n",
    "        \"in_axes\": 0,  # Input along axis 0 (batch dim)\n",
    "        \"out_axes\": 0,  # Output along axis 0 (batch dim)\n",
    "    },\n",
    "    # Configuration 2:\n",
    "    # - Parameters along axis 0 (separate params per layer)\n",
    "    # - Don't broadcast parameters\n",
    "    # - Split RNGs for parameters\n",
    "    # - Broadcast input to all layers\n",
    "    # - Output along axis 0 (batch dimension)\n",
    "    {\n",
    "        \"variable_axes\": {\"params\": 0},  # Parameters along axis 0 (per layer)\n",
    "        \"variable_broadcast\": False,  # Don't broadcast params\n",
    "        \"split_rngs\": {\"params\": True},  # Split RNGs for params\n",
    "        \"in_axes\": nn.broadcast,  # Broadcast input to all layers\n",
    "        \"out_axes\": 0,  # Output along axis 0 (batch dim)\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time for the subsequent JIT calls: 603.53 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'params': {'blocks': {'Dense_0': {'bias': (42, 512),\n",
       "    'kernel': (42, 512, 512)},\n",
       "   'self_attention': {'key': {'bias': (42, 4, 128),\n",
       "     'kernel': (42, 512, 4, 128)},\n",
       "    'out': {'bias': (42, 512), 'kernel': (42, 4, 128, 512)},\n",
       "    'query': {'bias': (42, 4, 128), 'kernel': (42, 512, 4, 128)},\n",
       "    'value': {'bias': (42, 4, 128), 'kernel': (42, 512, 4, 128)}}}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDX = 1\n",
    "class MyScanModule(nn.Module):\n",
    "    hidden_dim: int\n",
    "    num_layers: int\n",
    "    num_heads: int\n",
    "    dtype: jnp.dtype\n",
    "    \n",
    "    def setup(self):\n",
    "      self.blocks = nn.scan(\n",
    "         SimpleBlock,\n",
    "         length=self.num_layers,\n",
    "         **scan_args_list[IDX],\n",
    "\t\t\t)(\n",
    "\t\t\t\thidden_dim=self.hidden_dim,\n",
    "\t\t\t\tnum_heads=self.num_heads,\n",
    "\t\t\t\tdtype=self.dtype\n",
    "\t\t\t)\n",
    "\n",
    "    def __call__(self, x):\n",
    "      x, scan_out = self.blocks(x)\n",
    "      return x, scan_out\n",
    "\n",
    "scan_model = MyScanModule(hidden_dim=HIDDEN_DIM, num_layers=LAYERS, num_heads=NUM_HEADS, dtype=DTYPE)\n",
    "scan_params = scan_model.init(init_rng, dummy_input)\n",
    "\n",
    "compare_time(scan_model.apply, scan_params, input)\n",
    "\n",
    "jax.tree.map(jnp.shape, scan_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JAX Cost Analysis ===\n",
      "Total estimated memory accessed: 579.16 MB\n",
      "Estimated peak memory usage: 579.16 MB\n",
      "Estimated FLOPs: 57.880 GFLOPs\n",
      "Transcendental ops (exp, sin, etc.): 2752512\n",
      "\n",
      "\n",
      "=== JAX Cost Analysis ===\n",
      "Total estimated memory accessed: 148.77 MB\n",
      "Estimated peak memory usage: 210.00 MB\n",
      "Estimated FLOPs: 1.378 GFLOPs\n",
      "Transcendental ops (exp, sin, etc.): 65536\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For original model\n",
    "cost = jax.jit(model.apply).lower(params, input).compile().cost_analysis()\n",
    "print_cost_analysis(cost, show_utilization=False)\n",
    "\n",
    "# For scanned model\n",
    "scan_cost = jax.jit(scan_model.apply).lower(scan_params, input).compile().cost_analysis()\n",
    "print_cost_analysis(scan_cost, show_utilization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Example: Distributed LLM inference with KV cachingm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
